{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchxrayvision as xrv\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "from catalyst.data import Augmentor\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "\n",
    "batchsize=10\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainset = CovidCTDataset(root_dir='Images-processed',\n",
    "                              txt_COVID='Data-split/COVID/trainCT_COVID.txt',\n",
    "                              txt_NonCOVID='Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                              transform= train_transformer)\n",
    "    valset = CovidCTDataset(root_dir='Images-processed',\n",
    "                              txt_COVID='Data-split/COVID/valCT_COVID.txt',\n",
    "                              txt_NonCOVID='Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    testset = CovidCTDataset(root_dir='Images-processed',\n",
    "                              txt_COVID='Data-split/COVID/testCT_COVID.txt',\n",
    "                              txt_NonCOVID='Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    print(trainset.__len__())\n",
    "    print(valset.__len__())\n",
    "    print(testset.__len__())\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    test_loader = DataLoader(testset, batch_size=1, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = None\n",
    "device = 'cuda'\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#        data = data[:, 0, :, :]\n",
    "#        data = data[:, None, :, :]\n",
    "#         data, targets_a, targets_b, lam = mixup_data(data, target.long(), alpha, use_cuda=True)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        data.required_grad = True\n",
    "        output = model(data)\n",
    "        \n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "#         loss = mixup_criterion(criteria, output, targets_a, targets_b, lam)\n",
    "        train_loss += criteria(output, target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
    "    \n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            data.required_grad = True\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "          \n",
    "    return targetlist, scorelist, predlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testset, batch_size=1, drop_last=False, shuffle=False)\n",
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "\n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "    # Predict\n",
    "    counter = 0\n",
    "    for batch_index, batch_samples in enumerate(test_loader):\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "        print(data.shape)\n",
    "#         print(batch_samples)\n",
    "        output = model(data)\n",
    "#         print(output)\n",
    "\n",
    "        p = output\n",
    "#         print(p)\n",
    "        output[:,1].backward()\n",
    "#         print(output.shape)\n",
    "        test_loss += criteria(output, target.long())\n",
    "#         print(output.shape)\n",
    "        score = F.softmax(output, dim=1)\n",
    "#         print(output.shape)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "#         print(p.shape)\n",
    "        # get the gradient of the output with respect to the parameters of the model\n",
    "\n",
    "#         print(p.shape)\n",
    "#         print(p)\n",
    "        # pull the gradients out of the model\n",
    "        gradients = model.get_activations_gradient()\n",
    "\n",
    "        # pool the gradients across the channels\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "        # get the activations of the last convolutional layer\n",
    "        activations = model.get_activations(data).detach()\n",
    "        print(activations)\n",
    "        print(activations.shape)\n",
    "        print(gradients.shape)\n",
    "        # weight the channels by corresponding gradients\n",
    "        for i in range(2):\n",
    "            activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "        \n",
    "        # average the channels of the activations\n",
    "        heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "        # relu on top of the heatmap\n",
    "        # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "        heatmap = np.maximum(heatmap.cpu(), 0)\n",
    "\n",
    "        # normalize the heatmap\n",
    "        heatmap /= torch.max(heatmap)\n",
    "\n",
    "        # draw the heatmap\n",
    "        plt.matshow(heatmap.squeeze())\n",
    "        import cv2\n",
    "#         img = cv2.imread('./data/Elephant/test/1_kc-k_j53HOJH_sifhg4lHg.jpeg')\n",
    "\n",
    "#         print(heatmap)\n",
    "\n",
    "        heatmap = cv2.resize(np.array(heatmap), (data[0].shape[2], data[0].shape[1]))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img = heatmap * 0.4 + np.array(data[0].transpose(0,2).cpu()* 20)\n",
    "        cv2.imwrite('./mapDenseNet'+str(counter)+'.jpg', superimposed_img)\n",
    "        counter+=1\n",
    "#         cv2.imwrite('./orig.jpg',  np.array(data[0].transpose(0,2).cpu()))\n",
    "        \n",
    "#         pred.requires_grad = False\n",
    "#         scorelist.requires_grad = False\n",
    "#         score.requires_grad = False\n",
    "        \n",
    "        \n",
    "        correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "        targetcpu=target.long().cpu().numpy()\n",
    "        predlist=np.append(predlist, pred.detach().cpu().numpy())\n",
    "        scorelist=np.append(scorelist, score.detach().cpu().numpy()[:,1])\n",
    "        \n",
    "        targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "    return targetlist, scorelist, predlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet169\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        # get the pretrained DenseNet201 network\n",
    "        self.densenet = densenet169(pretrained=True)\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.densenet.features\n",
    "        \n",
    "        # add the average global pool\n",
    "        self.global_avg_pool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.densenet.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        if x.requires_grad: \n",
    "            h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        \n",
    "        # don't forget the pooling\n",
    "        x = self.global_avg_pool(x)\n",
    "        \n",
    "        x = x.view((x.shape[0],x.shape[1]))\n",
    "        \n",
    "# torch.Size([10, 3, 224, 224])\n",
    "# torch.Size([10, 1664, 7, 7])\n",
    "# torch.Size([10, 1664, 1, 1])\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)\n",
    "model = DenseNet().cuda()\n",
    "modelname = \"DenseNet169CAM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "bs = 10\n",
    "votenum = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "#scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 3000\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    targetlist, scorelist, predlist = val(epoch)\n",
    "    print('target',targetlist)\n",
    "    print('score',scorelist)\n",
    "    print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if epoch == total_epoch:\n",
    "        torch.save(model.state_dict(), \"model_backup/{}.pt\".format(modelname))  \n",
    "        \n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "# In[145]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "# test\n",
    "bs = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    \n",
    "    targetlist, scorelist, predlist = test(epoch)\n",
    "#     print('target',targetlist)\n",
    "#     print('score',scorelist)\n",
    "#     print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "    \n",
    "    TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
    "    TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
    "    FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
    "    FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
    "\n",
    "    print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "    print('TP+FP',TP+FP)\n",
    "    p = TP / (TP + FP)\n",
    "    print('precision',p)\n",
    "    p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    print('recall',r)\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print('F1',F1)\n",
    "    print('acc',acc)\n",
    "    AUC = roc_auc_score(targetlist, vote_score)\n",
    "    print('AUC', AUC)\n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        \n",
    "#         print('vote_pred', vote_pred)\n",
    "#         print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "#         f = open('model_result/{modelname}.txt', 'a+')\n",
    "#         f.write('precision, recall, F1, acc= \\n')\n",
    "#         f.writelines(str(p))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(r))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(F1))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(acc))\n",
    "#         f.writelines('\\n')\n",
    "#         f.close()\n",
    "        \n",
    "        \n",
    "        vote_pred = np.zeros((1,testset.__len__()))\n",
    "        vote_score = np.zeros(testset.__len__())\n",
    "        print('vote_pred',vote_pred)\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open(f'model_result/test_{modelname}.txt', 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "        f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = ((output.cpu()).data).numpy()\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.densenet.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features_conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCAM(feature_conv, weight_fc, class_idx):\n",
    "    _, nc, h, w = feature_conv.shape\n",
    "    cam = weight_fc[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    return [cam_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_softmax_params = list(model.features_conv.parameters())\n",
    "weight_softmax = np.squeeze(weight_softmax_params[0].cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_softmax_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import topk\n",
    "class_idx = topk(torch.from_numpy(predlist),1)[1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_layer = model._modules.get('layer4')\n",
    "\n",
    "activated_features = model.densenet.features\n",
    "overlay = getCAM(activated_features, weight_softmax, class_idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2,os\n",
    "import numpy as np\n",
    "import torch\n",
    "import  SimpleITK as sitk\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "from models.net2d import vgg19_bn,densenet161,vgg16,vgg19,resnet152\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x\n",
    "class ModelOutputs():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_extractor = FeatureExtractor(self.model.features, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations, output = self.feature_extractor(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.model.classifier(output)\n",
    "        return target_activations, output\n",
    "def preprocess_image(img):\n",
    "    means = [0,0,0]\n",
    "    stds = [1,1,1]\n",
    "\n",
    "    preprocessed_img = img.copy()[:, :, ::-1]\n",
    "    for i in range(3):\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "    preprocessed_img = \\\n",
    "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "    preprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "    preprocessed_img.unsqueeze_(0)\n",
    "    input = preprocessed_img.requires_grad_(True)\n",
    "    return input\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs(self.model, target_layer_names)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "        if self.cuda:\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input)\n",
    "        pred = np.exp(output.log_softmax(-1).cpu().data.numpy()[:, 1])\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.model.features.zero_grad()\n",
    "        self.model.classifier.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features[-1]\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]\n",
    "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, (224, 224))\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam,pred\n",
    "class GuidedBackpropReLU(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(self, input):\n",
    "        positive_mask = (input > 0).type_as(input)\n",
    "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
    "        self.save_for_backward(input, output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        input, output = self.saved_tensors\n",
    "        grad_input = None\n",
    "\n",
    "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
    "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input),\n",
    "                                   torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output,\n",
    "                                                 positive_mask_1), positive_mask_2)\n",
    "\n",
    "        return grad_input\n",
    "class GuidedBackpropReLUModel:\n",
    "    def __init__(self, model, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        # replace ReLU with GuidedBackpropReLU\n",
    "        for idx, module in self.model.features._modules.items():\n",
    "            if module.__class__.__name__ == 'ReLU':\n",
    "                self.model.features._modules[idx] = GuidedBackpropReLU.apply\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "        if self.cuda:\n",
    "            output = self.forward(input.cuda())\n",
    "        else:\n",
    "            output = self.forward(input)\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        # self.model.features.zero_grad()\n",
    "        # self.model.classifier.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        output = input.grad.cpu().data.numpy()\n",
    "        output = output[0, :, :, :]\n",
    "\n",
    "        return output\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--use-cuda', action='store_true', default=True,\n",
    "                        help='Use NVIDIA GPU acceleration')\n",
    "    parser.add_argument('--image-path', type=str, default='./examples/both.png',\n",
    "                        help='Input image path')\n",
    "    args = parser.parse_args()\n",
    "    args.use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "    if args.use_cuda:\n",
    "        print(\"Using GPU for acceleration\")\n",
    "    else:\n",
    "        print(\"Using CPU for computation\")\n",
    "\n",
    "    return args\n",
    "def deprocess_image(img,mask=None):\n",
    "    \"\"\" see https://github.com/jacobgil/keras-grad-cam/blob/master/grad-cam.py#L65 \"\"\"\n",
    "    img = img - np.mean(img)\n",
    "    img = img / (np.std(img) + 1e-5)\n",
    "    img = img * 0.1\n",
    "    img = img + 0.5\n",
    "    img[mask==0]=0.5\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    return np.uint8(img*255)\n",
    "def show_cam_on_image(img, mask,extral=None):\n",
    "    if isinstance(extral,np.ndarray):\n",
    "        mask=mask*extral[:,:,1]\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    cam[extral==0]=np.float32(img)[extral==0]\n",
    "    #cv2.imwrite(\"cam.jpg\", np.uint8(255 * cam))\n",
    "    return np.uint8(255 * cam)\n",
    "def model_get():\n",
    "    model = resnet152(2)\n",
    "\n",
    "    pretrained_dict = torch.load('../res152_lungattention_2train_lidc.pt')\n",
    "    # load only exists weights\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if\n",
    "                       k in model_dict.keys() and v.size() == model_dict[k].size()}\n",
    "    #print('matched keys:', len(pretrained_dict))\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "import glob\n",
    "if __name__ == '__main__':\n",
    "    \"\"\" python grad_cam.py <path_to_image>\n",
    "    1. Loads an image with opencv.\n",
    "    2. Preprocesses it for VGG19 and converts to a pytorch variable.\n",
    "    3. Makes a forward pass to find the category index with the highest score,\n",
    "    and computes intermediate activations.\n",
    "    Makes the visualization. \"\"\"\n",
    "\n",
    "    args = get_args()\n",
    "\n",
    "    # Can work with any model, but it assumes that the model has a\n",
    "    # feature method, and a classifier method,\n",
    "    # as in the VGG models in torchvision.\n",
    "    grad_cam = GradCam(model=model_get(), \\\n",
    "                       target_layer_names=[\"6\"], use_cuda=args.use_cuda)\n",
    "    gb_model = GuidedBackpropReLUModel(model=model_get(), use_cuda=args.use_cuda)\n",
    "    o_path = '../reader_study/cam/'\n",
    "    o_img_nii='../reader_study/cam/img'\n",
    "    o_msk_nii = '../reader_study/cam/mask'\n",
    "    o_lung_nii='../reader_study/cam/lung'\n",
    "    i_path = '../reader_study/mask_img'\n",
    "    i_path2 = '../reader_study/sig_img'\n",
    "\n",
    "    os.makedirs(o_path,exist_ok=True)\n",
    "    os.makedirs(o_img_nii, exist_ok=True)\n",
    "    os.makedirs(o_msk_nii, exist_ok=True)\n",
    "    os.makedirs(o_lung_nii, exist_ok=True)\n",
    "    for names in os.listdir(i_path):\n",
    "        if names[0]=='c':\n",
    "            continue\n",
    "        exlist=glob.glob('../ipt_results/cam_good/'+names.split('.jpg')[0]+'*')\n",
    "        if len(exlist)==0 and False:\n",
    "            continue\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(i_path, names), 1)\n",
    "            img_raw=cv2.imread(os.path.join(i_path2,names),1)\n",
    "            img_raw=np.float32(cv2.resize(img_raw,(224,224)))/255\n",
    "            img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "        except:\n",
    "            print(os.path.join(i_path2,names))\n",
    "            continue\n",
    "        input = preprocess_image(img)\n",
    "\n",
    "        # If None, returns the map for the highest scoring category.\n",
    "        # Otherwise, targets the requested index.\n",
    "        target_index = 1\n",
    "        mask,pred = grad_cam(input, target_index)\n",
    "        if pred[0]<0.8:\n",
    "            continue\n",
    "        #cam=show_cam_on_image(img_raw, mask)\n",
    "\n",
    "\n",
    "        gb = gb_model(input, index=target_index)\n",
    "        gb = gb.transpose((1, 2, 0))\n",
    "\n",
    "        cam_mask = cv2.merge([mask, mask, mask])\n",
    "        attention_area = cam_mask >0.55\n",
    "        #cam_gb = deprocess_image(cam_mask*gb)\n",
    "        gbt=gb.copy()\n",
    "        gb = deprocess_image(gb)\n",
    "        attention_area=attention_area*(np.abs(gb-128)>64)\n",
    "        attention_area=attention_area[:,:,0]+attention_area[:,:,1]+attention_area[:,:,2]\n",
    "        attention_area=(attention_area>=1).astype(np.uint8)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        attention_area = cv2.morphologyEx(attention_area, cv2.MORPH_CLOSE, kernel)\n",
    "        lung_mask=cv2.erode(img[:,:,2],kernel)\n",
    "        attention_area=attention_area*lung_mask\n",
    "        attention_area = np.stack([attention_area, attention_area, attention_area], -1)\n",
    "        #if np.sum(attention_area)<=10:\n",
    "        #    continue\n",
    "        cam = show_cam_on_image(img_raw, mask,attention_area)\n",
    "        cam_gb = deprocess_image(cam_mask * gbt,attention_area)\n",
    "\n",
    "        I = np.concatenate([img_raw*255,cam,cam_gb],1)\n",
    "\n",
    "        output_name = names.split('.jpg')[0] + '_{:.2f}.jpg'.format(pred[0])\n",
    "        output_path = os.path.join(o_path, output_name)\n",
    "        attention_area=np.array(attention_area>0.55,np.uint8)\n",
    "        cv2.imwrite(output_path, I)\n",
    "        Inii=sitk.GetImageFromArray(img_raw[:,:,1]*255)\n",
    "        Lnii = sitk.GetImageFromArray(img[:, :, 2])\n",
    "        Mnii=sitk.GetImageFromArray(attention_area[:,:,1])\n",
    "        sitk.WriteImage(Inii,os.path.join(o_img_nii,output_name[:-4]+'.nii'))\n",
    "        sitk.WriteImage(Mnii,os.path.join(o_msk_nii, output_name[:-4]+ '.nii') )\n",
    "        sitk.WriteImage(Lnii, os.path.join(o_lung_nii, output_name[:-4] + '.nii'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
